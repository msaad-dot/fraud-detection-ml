{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "a53439f0-352d-44bf-b8ef-4d7655de4a81",
   "metadata": {},
   "source": [
    "## 02_preprocessing — Data Preparation and Feature Scaling"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a17be325-b7c2-48e1-9c1d-c174f80f8556",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from pathlib import Path\n",
    "...\n",
    "from sklearn.model_selection import train_test_split\n",
    "...\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "...\n",
    "import joblib\n",
    "import os\n",
    "\n",
    "PROJECT_ROOT = Path().resolve().parent\n",
    "DATA_PATH = PROJECT_ROOT / \"data\" / \"creditcard.csv\"\n",
    "\n",
    "# Load the dataset\n",
    "df = pd.read_csv(DATA_PATH)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1dacced6-6826-4dc3-b1bb-2fbc8df0535e",
   "metadata": {},
   "source": [
    "## Preprocessing Strategy\n",
    "\n",
    "- The task is formulated as a binary classification problem, where the goal is to detect\n",
    "fraudulent transactions.\n",
    "\n",
    "- The target variable is highly imbalanced, therefore class weighting will be used during\n",
    "model training instead of resampling to preserve the original data distribution.\n",
    "\n",
    "- PCA-transformed features (V1–V28) are already scaled and do not require additional normalization.\n",
    "\n",
    "- The Time and Amount features will be scaled using StandardScaler, as their original\n",
    "distributions differ significantly from the PCA-transformed features.\n",
    "\n",
    "- A stratified train-test split will be applied to maintain the original class distribution\n",
    "in both training and test sets."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b5f1e5fe-9880-41c3-9635-5fc696db7718",
   "metadata": {},
   "source": [
    "## Feature–Target Separation\n",
    "\n",
    "In this step, we separate the dataset into input features (X) and the target variable (y).\n",
    "The target variable represents whether a transaction is fraudulent (1) or normal (0)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "17b477fd-35f4-4367-ba83-5ee7cb376b09",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Separate features and target\n",
    "# X contains all input features\n",
    "# y contains the target label (fraud indicator)\n",
    "X = df.drop(columns=['Class'])\n",
    "y = df['Class']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "29a50ef6-d6a6-4b74-8666-d513f64f9b6b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Verify feature matrix dimensions\n",
    "X.shape\n",
    "# Verify class distribution in target\n",
    "y.value_counts()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ac592f84-76f3-4cb8-981b-ddb66dbdd7cc",
   "metadata": {},
   "source": [
    "## Train-Test Split\n",
    "\n",
    "- The dataset is split into training and testing sets.\n",
    "- Stratified sampling is used to preserve the original class distribution\n",
    "due to the severe class imbalance."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b7f0a84a-cf68-4418-9d4c-0336f6620190",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Split the data into training and testing sets\n",
    "# stratify=y ensures the class distribution is preserved\n",
    "# random_state is set for reproducibility\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(\n",
    "    X,\n",
    "    y,\n",
    "    test_size=0.2,\n",
    "    stratify=y,\n",
    "    random_state=42\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d93f89b9-c484-49e2-8012-ea79b9b3ef25",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Verify that class proportions are preserved after splitting\n",
    "print(y_train.value_counts(normalize=True))\n",
    "print(y_test.value_counts(normalize=True))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5c42fb8e-1ed7-43b4-be38-8e6494979806",
   "metadata": {},
   "source": [
    "### Key Observation\n",
    "\n",
    "The class distribution in both training and test sets closely matches the\n",
    "original dataset, confirming that stratified sampling was applied correctly."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "78c99cdd-e146-45f7-8c5f-b6548cd547a7",
   "metadata": {},
   "source": [
    "## Feature Scaling\n",
    "\n",
    "Although most features are already scaled due to PCA transformation (V1–V28),\n",
    "the Time and Amount features require normalization to ensure consistent\n",
    "feature scales during model training."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b7232651-055a-4300-a9a6-69b561f13b51",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Initialize the scaler\n",
    "scaler = StandardScaler()\n",
    "\n",
    "# Columns that require scaling\n",
    "scale_cols = ['Time', 'Amount']\n",
    "\n",
    "# Create copies to avoid SettingWithCopyWarning\n",
    "X_train = X_train.copy()\n",
    "X_test = X_test.copy()\n",
    "\n",
    "# Fit on training data only\n",
    "X_train.loc[:, scale_cols] = scaler.fit_transform(X_train[scale_cols])\n",
    "\n",
    "# Apply the same transformation to test data\n",
    "X_test.loc[:, scale_cols] = scaler.transform(X_test[scale_cols])\n",
    "\n",
    "# Scaling verification\n",
    "X_train[scale_cols].describe()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5040d404-5e12-4dea-b7b4-a862683c7ff9",
   "metadata": {},
   "source": [
    "## Scaling Verification & Key Observations\n",
    "\n",
    "- The scaled features (`Time` and `Amount`) have a mean approximately equal to **0**\n",
    "  and a standard deviation close to **1**, confirming correct standardization.\n",
    "\n",
    "- StandardScaler was selected instead of RobustScaler because the majority of features\n",
    "are already PCA-transformed and approximately standardized,\n",
    "consistent scaling is preferred to preserve the relative structure learned by linear models.\n",
    "  \n",
    "- Feature scaling was applied **after the train-test split** to prevent data leakage.\n",
    "\n",
    "- Only `Time` and `Amount` were scaled, since the PCA-based features (`V1–V28`)\n",
    "  are already standardized by the dataset provider.\n",
    "\n",
    "- The fitted scaler is saved to ensure consistent preprocessing during inference\n",
    "and future model deployment."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2b42a976-51d8-417f-9e88-4cd133ca1325",
   "metadata": {},
   "source": [
    "## Linking Preprocessing with Modeling\n",
    "\n",
    "To maintain a clean and modular machine learning workflow, the outputs of the\n",
    "preprocessing stage are explicitly saved and later loaded by the modeling stage.\n",
    "\n",
    "This approach ensures that:\n",
    "- Each notebook remains fully independent and reproducible.\n",
    "- Preprocessing decisions are applied consistently during model training.\n",
    "- There is no reliance on shared notebook state or execution order.\n",
    "- The workflow more closely resembles real-world production pipelines, where\n",
    "  data preprocessing and model training are decoupled stages.\n",
    "\n",
    "The preprocessed feature matrices, target splits, and fitted scaler are saved as\n",
    "versioned artifacts and loaded explicitly by the modeling stage."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "592f8f39-f36f-4206-9ac1-9fb8796f201b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Ensure artifacts directory exists\n",
    "os.makedirs(\"artifacts\", exist_ok=True)\n",
    "\n",
    "# Persist preprocessing artifacts for reuse during model training and inference\n",
    "joblib.dump(X_train, \"artifacts/X_train.pkl\")\n",
    "joblib.dump(X_test, \"artifacts/X_test.pkl\")\n",
    "joblib.dump(y_train, \"artifacts/y_train.pkl\")\n",
    "joblib.dump(y_test, \"artifacts/y_test.pkl\")\n",
    "joblib.dump(scaler, \"artifacts/standard_scaler.pkl\")\n",
    "\n",
    "print(\"Preprocessing artifacts saved successfully.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "82044ddd-b1a4-407c-ba0d-25c8a8b5778a",
   "metadata": {},
   "source": [
    "## Preprocessing Outputs\n",
    "\n",
    "- `X_train`, `X_test`: Feature matrices after scaling\n",
    "- `y_train`, `y_test`: Corresponding target labels\n",
    "- `standard_scaler`: Fitted scaler to ensure consistent transformations during\n",
    "  inference and future deployment"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python (fraud-ml)",
   "language": "python",
   "name": "fraud-ml"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.14.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
