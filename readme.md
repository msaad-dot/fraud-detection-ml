# ğŸ’³ Fraud Detection â€” Machine Learning Pipeline

## ğŸ“Œ Project Overview
This project tackles a **highly imbalanced credit card fraud detection** problem,
where the goal is to maximize fraud detection while controlling false positive alerts
that negatively impact customer experience.

Fraud detection is treated as a **cost-sensitive classification problem**, where
false negatives (missed fraud) typically incur higher cost than false positives.


## ğŸ“Š Dataset
The dataset contains anonymized credit card transactions:
- Features **V1â€“V28** are **PCA-transformed**
- **Time** and **Amount** represent transaction time and value
- Target variable **Class**:
  - `0` â†’ Normal transaction  
  - `1` â†’ Fraudulent transaction  

Fraud cases represent approximately **0.17%** of the dataset, making
traditional accuracy-based evaluation misleading.

> The dataset is excluded from version control and should be placed locally under the `data/` directory.

> Dataset source: Kaggle â€” Credit Card Fraud Dataset.

## ğŸ—‚ï¸ Project Structure
> Trained models and preprocessing artifacts are persisted locally for
> reproducibility but are excluded from version control.

```text
fraud-detection-ml/
â”œâ”€â”€ notebooks/
â”‚   â”œâ”€â”€ 01_eda.ipynb
â”‚   â”œâ”€â”€ 02_preprocessing.ipynb
â”‚   â”œâ”€â”€ 03_modeling.ipynb
â”‚   â”œâ”€â”€ 04_evaluation.ipynb
â”‚   â””â”€â”€ 05_model_comparison.ipynb
â”‚
â”œâ”€â”€ artifacts/
â”‚
â”œâ”€â”€ models/
â”‚
â”œâ”€â”€ images/
â”‚   â””â”€â”€ pr_curve_comparison.png
â”‚
â”œâ”€â”€ requirements.txt
â””â”€â”€ README.md
```
## ğŸ” Machine Learning Pipeline

```text
Raw Dataset (creditcard.csv)
        â†“
01_eda â€” Exploratory Data Analysis
        â†“
02_preprocessing
  â€¢ Stratified train/test split
  â€¢ Feature scaling (Time, Amount)
  â€¢ Artifact persistence
        â†“
03_modeling
  â€¢ Logistic Regression (baseline)
        â†“
04_evaluation
  â€¢ PR-AUC / ROC-AUC
  â€¢ Threshold tuning
        â†“
05_model_comparison
  â€¢ Logistic Regression
  â€¢ Random Forest
  â€¢ XGBoost
  â€¢ Business-aware model selection
```

## âš™ï¸ Modeling Strategy
- Severe class imbalance handled using **class-weighted training**
- **PR-AUC** prioritized over accuracy due to extreme imbalance
- **Probability-based evaluation** used instead of hard predictions
- **Threshold tuning** aligned with operational and business risk
- Preprocessing, modeling, and evaluation are fully **decoupled**
  to resemble real-world ML pipelines
- Different probability distributions across models required
  **model-specific threshold selection**




## ğŸ“Š Final Model Comparison

| Model | PR-AUC | Threshold | Precision | Recall | False Positives |
|------|--------|-----------|-----------|--------|-----------------|
| Logistic Regression | 0.716 | 0.70 | 0.12 | 0.91 | 644 |
| Random Forest | 0.854 | 0.35 | 0.94 | 0.81 | 5 |
| **XGBoost** | **0.861** | **0.50** | **0.67** | **0.86** | **41** |


## âœ… Final Model Selection
- Logistic Regression achieved high fraud recall but generated an excessive
  number of false positive alerts.
- Random Forest minimized false positives but missed a larger portion of fraud.
- **XGBoost achieved the best overall balance**, combining:
  - Highest ranking performance (PR-AUC)
  - Strong fraud recall
  - Substantial reduction in false positives

â¡ï¸ **XGBoost was selected as the preferred production candidate under a
moderate risk tolerance setting.**

> **Key takeaway:** Model selection in fraud detection is driven by business
> trade-offs rather than metric maximization.

## ğŸ“ˆ Precisionâ€“Recall Curve Comparison
![Precisionâ€“Recall Curve](images/pr_curve_comparison.png)


## ğŸ› ï¸ Tech Stack
- Python
- scikit-learn
- XGBoost
- NumPy / Pandas
- Matplotlib


## ğŸ‘¤ Author
**Mohamed Saad**
